var data={"title":"Evaluating diagnostic tests","body":"<div id=\"topicContent\" class=\"utdArticleSection utdStyle\"><div id=\"topicTitle\">Evaluating diagnostic tests</div><dl id=\"topicContributors\"><dt><span> </span>Authors:</dt><dd><a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/contributors\" class=\"contributor contributor_credentials\">Neal G Mahutte, MD</a></dd><dd><a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/contributors\" class=\"contributor contributor_credentials\">Antoni J Duleba, MD</a></dd><dt><span> </span>Section Editor:</dt><dd><a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/contributors\" class=\"contributor contributor_credentials\">Joann G Elmore, MD, MPH</a></dd><dt><span> </span>Deputy Editor:</dt><dd><a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/contributors\" class=\"contributor contributor_credentials\">Carrie Armsby, MD, MPH</a></dd></dl><p class=\"disclosureLink\"><a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/contributor-disclosure\" class=\"contributor contributor_credentials\">Contributor Disclosures</a></p><div id=\"reviewProcess\"><span>All topics are updated as new evidence becomes available and our <a href=\"https://www.uptodate.com/home/editorial-policy\" target=\"_blank\" class=\"policy policy_editorialpolicy\">peer review process</a> is complete.</span></div><div id=\"literatureReviewDate\"><span class=\"emphasis\">Literature review current through:</span>&#160;Feb 2018.&#160;&#124;&#160;<span class=\"emphasis\">This topic last updated:</span>&#160;Mar 23, 2017.</div><div id=\"topicWhatsNewContainer\"></div><div id=\"topicText\"><p class=\"headingAnchor\" id=\"H1\"><span class=\"h1\">INTRODUCTION</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>The introduction of new diagnostic tests that claim to improve screening or provide definitive diagnosis is a major dilemma for all clinicians. The decision to embrace or reject these tests is often made individually with incomplete information and without thoughtful reflection.</p><p>In this topic review we will outline a simple seven-step process that can be used to evaluate the utility of any diagnostic test:</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Can the test be reliably performed?</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Was the test evaluated on an appropriate population?</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Was an appropriate gold standard used?</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Was an appropriate cut-off value chosen to optimize sensitivity and specificity?</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>What are the positive and negative likelihood ratios?</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>How well does the test perform in specific populations?</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>What is the balance between cost of the disease and cost of the test?</p><p/><p>A catalog of common biostatistical and epidemiological terms encountered in the medical literature, an evidence based approach to prevention, and issues around hypothesis testing are presented separately. (See <a href=\"topic.htm?path=glossary-of-common-biostatistical-and-epidemiological-terms\" class=\"medical medical_review\">&quot;Glossary of common biostatistical and epidemiological terms&quot;</a> and <a href=\"topic.htm?path=evidence-based-approach-to-prevention\" class=\"medical medical_review\">&quot;Evidence-based approach to prevention&quot;</a> and <a href=\"topic.htm?path=proof-p-values-and-hypothesis-testing\" class=\"medical medical_review\">&quot;Proof, p-values, and hypothesis testing&quot;</a>.)</p><p class=\"headingAnchor\" id=\"H2\"><span class=\"h1\">CAN THE TEST BE PERFORMED RELIABLY?</span></p><p class=\"headingAnchor\" id=\"H3\"><span class=\"h2\">Accuracy and precision</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>It is helpful to determine the extent to which the test is accurate, precise, and user dependent to objectively answer this question. &quot;Accuracy&quot; refers to the ability of the test to actually measure what it claims to measure, and is defined as the proportion of all test results (both positive and negative) that are correct (<a href=\"image.htm?imageKey=PC%2F55297\" class=\"graphic graphic_table graphicRef55297 \">table 1</a>). Precision refers to the ability of the test to reproduce the same result when repeated on the same patient or sample. The two concepts are related, but different. For example, a test could be precise, but not accurate if on three occasions it produced roughly the same result, but that result differed greatly from the actual value determined by a reference-standard. Both accuracy and precision may be presented in the form of a confidence interval (CI) or standard error (SE).</p><p class=\"headingAnchor\" id=\"H4\"><span class=\"h2\">Expertise</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>One of the great challenges in evaluating a diagnostic test is determining to what extent user expertise influences accuracy and precision. Studies in the literature often emanate from tertiary care centers with advanced capabilities for diagnostic equipment and personnel. Such environments may bear little resemblance to the facilities found at a local level. As an example, high &quot;user dependence&quot; makes it difficult to apply advances in screening ultrasonography found at specialized centers to the population at large [<a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/abstract/1\" class=\"abstract_t\">1</a>]. The test may be accurate and precise in an expert's hands, but may be imprecise, inaccurate, and unreliable when performed by a less experienced practitioner. These factors should be taken into account when determining if a given test should be implemented in a given situation.</p><p class=\"headingAnchor\" id=\"H5\"><span class=\"h1\">WAS THE TEST EVALUATED ON AN APPROPRIATE POPULATION?</span></p><p class=\"headingAnchor\" id=\"H6\"><span class=\"h2\">Population</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>This step examines the population from which test data was derived, a point that is often overlooked. A test should be conducted on a broad spectrum of patients with and without the disorder in question to maximize generalizability. Those with the disorder should represent all stages and manifestations of the disease. Even more importantly, individuals without the disorder should have some clinical manifestations similar to, and perhaps easily confused with, the disease in question. This is critical in demonstrating the ability of the test to distinguish among clinical entities in the differential diagnosis.</p><p>As an example, the utility of obtaining a serum CA125 concentration for detection of endometriosis depends upon studying a population that includes a range of patients with minimal, mild, moderate, and severe endometriosis. If the study population has a disproportionate number of women with severe disease, this might falsely inflate the capability of the test to identify cases. It is also essential to include a large cohort of patients without endometriosis, but with similar signs or symptoms (eg, dysmenorrhea, dyspareunia, pelvic pain, infertility, adnexal mass, fibroids). Neglecting to include these patients might falsely inflate the performance of the test.</p><p class=\"headingAnchor\" id=\"H7\"><span class=\"h2\">Sample size</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>Sample size is part of the question of population appropriateness. An adequate number of patients must be studied to encompass a broad spectrum of manifestations in diseased and nondiseased subjects. However, an overly large sample size may detect a statistically significant test difference that is not clinically meaningful, while a sample size that is too small may yield inconclusive results due to low power.</p><p>One indirect way of evaluating sample size is to examine the confidence intervals for sensitivity, specificity, and likelihood ratio (see below) reported in the study.</p><p class=\"headingAnchor\" id=\"H8\"><span class=\"h1\">WAS AN APPROPRIATE REFERENCE-STANDARD USED?</span></p><p class=\"headingAnchor\" id=\"H9\"><span class=\"h2\">Reference-standards</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>Evaluation of a test necessarily involves comparison with a reference-standard. Ideally, a reference-standard allows unambiguous identification of diseased and nondiseased patients. However, in the real world, reference-standards often involve some degree of error or user-dependence.</p><p>As an example, histopathology is often used as a reference-standard for the diagnosis of endometriosis; however, histopathology is not infallible. Cases can be misdiagnosed because of sampling error or individual differences among pathologists in histological interpretation. The presence of ectopic endometrial glands, but not stroma (or vice versa), in a woman with clinical signs and symptoms of endometriosis is suggestive of this disorder, but does not meet strict criteria for the disease (ie, ectopically located endometrial glands and stroma). By comparison, does an asymptomatic woman have endometriosis if a random biopsy of her normal appearing peritoneum finds endometrial glands and stroma? These questions address issues of both disease definition and what is normal.</p><p>Real world considerations compel us to use practical definitions. Reference-standards represent &quot;the best we've got&quot; for distinguishing normal from abnormal. The reference-standard is the test that thus far has been shown to most reliably detect the disease. Therefore, any new test that may purport to have value must be compared with the reference-standard if we are to minimize the chance of misdiagnosis.</p><p class=\"headingAnchor\" id=\"H10\"><span class=\"h2\">Defining normal</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>&quot;Normal&quot; is a deceptive term. While it is used commonly to refer to good health or the absence of disease, defining normal can be complex and arbitrary. Many tests define normal based upon assigned cut-off values that assume a fixed prevalence of disease. Intrauterine growth restriction (IUGR), for example, may be defined as an estimated fetal weight less than the 10th percentile, less than the 5th percentile, or less than two standard deviations from the mean. Such definitions may be convenient, but clearly do not reflect the true prevalence of the disease in divergent populations.</p><p>In addition, the cutoff value may not accurately reflect the diseased condition. As an example, the concept of growth restriction implies a pathologic process resulting in failure to achieve the genetically programmed size. A neonate with a birth weight at the 12th percentile who has three older brothers whose birth weights were at the 90th percentile would be categorized as normal under the standard definitions described above, even though the neonate appears not to have reached its genetic potential. In contrast, an infant whose actual weight and true genetic potential were at the 4th percentile might be mislabeled IUGR.</p><p class=\"headingAnchor\" id=\"H11\"><span class=\"h1\">WAS AN APPROPRIATE CUT-OFF VALUE CHOSEN TO OPTIMIZE SENSITIVITY AND SPECIFICITY?</span></p><p class=\"headingAnchor\" id=\"H12\"><span class=\"h2\">Balancing sensitivity and specificity</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>A cut-off value must be chosen to separate normal from abnormal. Selecting this value virtually always involves balancing sensitivity and specificity, although the actual value may be arbitrary.</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Sensitivity is the probability that an individual with the disease will test positive. It is the number of patients with a positive test who have the disease (true positives) divided by all patients who have the disease. A test with high sensitivity will not miss many patients who have the disease (ie, low false negative rate).</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Specificity is the probability that an individual without the disease will test negative. It is the number of patients who have a negative test and do not have the disease (true negatives) divided by the number of patients who do not have the disease. A test with high specificity will infrequently identify patients as having a disease when they do not (ie, low false positive results).</p><p/><p class=\"headingAnchor\" id=\"H13\"><span class=\"h2\">Two by two tables</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>A two-by-two table (<a href=\"image.htm?imageKey=OBGYN%2F73504\" class=\"graphic graphic_table graphicRef73504 \">table 2</a>) is the simplest way to calculate sensitivity and specificity. However, understanding the interrelationship among sensitivity, specificity, and cut-off values is easiest in graphic form (<a href=\"image.htm?imageKey=OBGYN%2F73854\" class=\"graphic graphic_figure graphicRef73854 \">figure 1</a>).</p><p>Two-by-two tables can also be used for calculating the false positive and false negative rates.</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>The false positive rate = false positives <span class=\"nowrap\">/</span> (false positives + true negatives). It is also equal to 1- specificity.</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>The false negative rate = false negatives <span class=\"nowrap\">/</span> (false negatives + true positives). It is also equal to 1 &ndash; sensitivity.</p><p/><p>An ideal test maximizes both sensitivity and specificity, thereby minimizing the false positive and false negative rates.</p><p class=\"headingAnchor\" id=\"H14\"><span class=\"h2\">Receiver operating characteristic curves</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>Receiver operating characteristic (ROC) curves allow one to identify the cut-off value that minimizes both false positives and false negatives. A ROC curve plots sensitivity on the y axis and 1 &ndash; specificity on the x axis (<a href=\"image.htm?imageKey=OBGYN%2F82175\" class=\"graphic graphic_figure graphicRef82175 \">figure 2</a>). Applying a variety of cutoff values to the same reference population allows one to generate the curve. The perfect test would have a cut-off value that allowed an exact split of diseased and nondiseased populations (ie, a cut-off that gave both 100 percent sensitivity and 100 percent specificity). It would plot as a right angle with the fulcrum in the far upper left corner (x = 0, y = 1). This case, however, is very rare. For the vast majority of cases, as one moves from left to right on the ROC curve the sensitivity increases while the specificity decreases.</p><p>Calculation of the area under the ROC curve allows comparison of different tests. A perfect test has an area under the curve equal to one. Therefore, the closer the area under the curve is to one, the better the test. Similarly, if one wants to know the cut-off value for a test that minimizes both false positives and false negatives (and hence maximizes both sensitivity and specificity), one would select the point on the ROC curve closest to the far upper left corner (x = 0, y = 1).</p><p>However, finding the right balance between optimal sensitivity and specificity may not involve simultaneously minimizing false positives and false negatives in all situations. For example, when screening for a deadly disease that is curable, it may be desirable to accept more false positives (lower specificity) in return for fewer false negatives (higher sensitivity). ROC curves allow a more thorough evaluation of a test and potential cut-off values, but are not the ultimate arbiters of how to set sensitivity and specificity.</p><p class=\"headingAnchor\" id=\"H15\"><span class=\"h1\">WHAT ARE THE POSITIVE AND NEGATIVE LIKELIHOOD RATIOS?</span></p><p>Epidemiologists have devised another method by which to judge diagnostic tests: positive and negative likelihood ratios which, like sensitivity and specificity, are independent of disease prevalence.</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>The positive likelihood ratio = sensitivity <span class=\"nowrap\">/</span> (1 &ndash; specificity). This ratio divides the probability that a patient with the disease will test positive by the probability that a patient without the disease will test positive. It can also be written as the true positive rate <span class=\"nowrap\">/</span> false positive rate. Thus, the higher the positive likelihood ratio, the better the test (a perfect test has a positive likelihood ratio equal to infinity).</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>The negative likelihood ratio = (1 &ndash; sensitivity) <span class=\"nowrap\">/</span> specificity. This ratio divides the probability that a patient with the disease will test negative by the probability that a patient without the disease will test negative. It can also be written as the false negative rate <span class=\"nowrap\">/</span> true negative rate. Therefore, the lower the negative likelihood ratio, the better the test (a perfect test has a negative likelihood ratio of zero).</p><p/><p>In most instances one can evaluate likelihood ratios as shown in the table (<a href=\"image.htm?imageKey=OBGYN%2F69816\" class=\"graphic graphic_table graphicRef69816 \">table 3</a>). For example, suppose you were attempting to interpret the significance of a CA125 value of 80 in a 46-year-old woman with an ovarian cyst. If 70 percent of patients with ovarian cancer have a CA125 at this level, but 35 percent of patients with benign cysts have a CA125 at the same level, then the positive likelihood ratio would only be two (ie, 0.<span class=\"nowrap\">70/0</span>.35). This would be considered a poor test for diagnosis of cancer.</p><p>Although likelihood ratios are independent of disease prevalence, their direct validity is only within the original study population. They are generalizable to other populations to the extent that:</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>The test can be reliably performed with minimal interobserver and intraobserver variation.</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>The study population(s) from which the values were derived was adequate in size and composition of normal and diseased phenotypes.</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>An appropriate reference-standard was used.</p><p/><p>If a diagnostic test was investigated in a narrow subpopulation or the test relied heavily on user <span class=\"nowrap\">skill/interpretation,</span> then the sensitivity, specificity, and likelihood ratios reported in the study may not be generalizable outside the original research population. In other words, the test performance parameters may have internal validity, but not external validity.</p><p class=\"headingAnchor\" id=\"H16\"><span class=\"h1\">HOW WELL DOES THE TEST PERFORM IN SPECIFIC POPULATIONS?</span></p><p class=\"headingAnchor\" id=\"H17\"><span class=\"h2\">Disease prevalence</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>If the sensitivity, specificity, and likelihood ratios are well defined, the penultimate factor determining the utility of a test is disease prevalence (<a href=\"topic.htm?path=calculator-post-test-probability-from-pre-test-probability-sensitivity-and-specificity\" class=\"calc calc_professional\">calculator 1</a> and <a href=\"topic.htm?path=calculator-post-test-probability-from-likelihood-ratios-and-multiple-test-results\" class=\"calc calc_professional\">calculator 2</a>). The usefulness of a positive test decreases as disease prevalence decreases. This concept is the basis of predictive values or post-test probabilities.</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Positive predictive value (PPV) refers to the probability that a positive test correctly identifies an individual who actually has the disease. It is computed from two-by-two tables: true positives <span class=\"nowrap\">/(true</span> positives + false positives) (<a href=\"image.htm?imageKey=GAST%2F77832\" class=\"graphic graphic_table graphicRef77832 \">table 4</a>).</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Negative predictive value (NPV) refers to the probability that a negative test correctly identifies an individual who does not have the disease. It is computed from two-by-two tables: true negatives <span class=\"nowrap\">/(false</span> negatives + true negatives) (<a href=\"image.htm?imageKey=GAST%2F77832\" class=\"graphic graphic_table graphicRef77832 \">table 4</a>).</p><p/><p>For example, assuming a constant sensitivity and specificity, the PPV and NPV for a disease with prevalence of 10, 1, or 0.1 percent are shown in a table (<a href=\"image.htm?imageKey=OBGYN%2F51763\" class=\"graphic graphic_table graphicRef51763 \">table 5</a>). This example illustrates how a positive result from the same test with near-perfect sensitivity (99 percent) and high specificity (90 percent) may have completely different significance depending upon the baseline prevalence of disease in the population. When applied to a population in which the disease is common (prevalence = 10 percent), the positive predictive value is 53 percent. By comparison, when applied to a different population in which the disease is uncommon (prevalence = 0.1 percent), the positive predictive value is only 1 percent; thus 99 percent of all individuals who test positive are actually free of the disease. All the test has accomplished in this population is to slightly upgrade the probability of disease from extremely unlikely (0.1 percent) to very unlikely (1 percent), and in the process subjected numerous individuals without the disease to further testing. A second example, using a different combination of sensitivity, specificity, and prevalence, is illustrated in a figure (<a href=\"image.htm?imageKey=PC%2F68072\" class=\"graphic graphic_figure graphicRef68072 \">figure 3</a>).</p><p>A clinical example of the importance of prevalence on test utility is in fetal fibronectin testing for prediction of preterm delivery. A systematic review reported the overall sensitivity and specificity of this test (in symptomatic and asymptomatic patients) for delivery before 34 weeks was 52 and 85 percent, respectively [<a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/abstract/2\" class=\"abstract_t\">2</a>]. If the prevalence of preterm birth in an asymptomatic low risk population is 10 percent, then PPV of a positive fetal fibronectin result would be 28 percent, whereas in a high risk symptomatic population with a prevalence of preterm birth of 50 percent, the PPV would be 78 percent.</p><p>The internet site (<a href=\"http://faculty.vassar.edu/lowry/clin1.html&amp;token=ZH2FYHSo99+YlDaqVJcSEkxyPFbRvpo0Rw6P6ZFGHK/g5I0tKJzYuhL3sUQG+koyiES6Iadxz1X/+R84nDi8AA==&amp;TOPIC_ID=2769\" target=\"_blank\" class=\"external\">http://faculty.vassar.edu/lowry/clin1.html</a>) allows one to perform calculations from entered data and thereby illustrate the relationship between pretest probabilities (prevalence), likelihood ratios and post-test probabilities (predictive values).</p><p class=\"headingAnchor\" id=\"H18\"><span class=\"h1\">WHAT IS THE BALANCE BETWEEN COST OF THE DISEASE AND COST OF THE TEST?</span></p><p>The final judgment involved in considering the value of a test is the balance between cost of the disease and cost of the test. These costs involve charges to an individual, to an insurer, to an institution, or to society. We live in a world with finite resources, but burgeoning demand for better health care, more accurate tests, and rapid diagnosis. Cost is often the determinant in deciding when, where, and how a diagnostic test is utilized.</p><p>A society and its health care payers and providers might be willing to accept low positive predictive values in return for saved lives for a rare disease that is universally fatal, but easily curable. By comparison, an accurate but extremely expensive test might be less desirable than one of lesser quality if the consequences of misdiagnosis are not serious.</p><p>Cost analysis involves direct monetary costs, as well as all of the indirect costs of disease, testing, and misdiagnosis. Unfortunately, these costs are often rough estimates, which hampers the accuracy of this type of analysis. In addition, cost studies typically suffer from poor external validity; values used in the analysis may not be readily generalizable to other areas of the country, other health systems, or other countries. Finally, because markets are never static, costs often change, with the potential to alter or entirely invalidate the thrust of the analysis.</p><p class=\"headingAnchor\" id=\"H826056464\"><span class=\"h1\">SUMMARY AND RECOMMENDATIONS</span><span class=\"headingEndMark\">&#160;&#8212;&#160;</span>It is not an easy task to evaluate fully the utility of a diagnostic test; many variables must be considered. This topic review attempts to provide a framework from which any test may be objectively and systematically analyzed. The seven steps outlined need not be followed in exact order. For example, one may wish to consider cost and predictive values before delving deeper into the validity of applying the test to a specific population. Nevertheless, careful consideration of all seven questions is important in making a final decision regarding the utility of a diagnostic test.</p><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>In order to determine the reliability of a test, it is helpful to assess the extent to which the test is accurate, precise, and user dependent. (See <a href=\"#H2\" class=\"local\">'Can the test be performed reliably?'</a> above.)</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>A test should be evaluated on a broad spectrum of patients with and without the disorder in question to maximize generalizability. (See <a href=\"#H5\" class=\"local\">'Was the test evaluated on an appropriate population?'</a> above.)</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>A reference-standard allows unambiguous identification of diseased and nondiseased patients. However, in the real world, reference-standards often involve some degree of error or user-dependence. (See <a href=\"#H8\" class=\"local\">'Was an appropriate reference-standard used?'</a> above.)</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>A cut-off value must be chosen to separate normal from abnormal. Selecting this value virtually always involves balancing sensitivity and specificity, although the actual value may be arbitrary (<a href=\"image.htm?imageKey=OBGYN%2F73854\" class=\"graphic graphic_figure graphicRef73854 \">figure 1</a>). (See <a href=\"#H11\" class=\"local\">'Was an appropriate cut-off value chosen to optimize sensitivity and specificity?'</a> above.)</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>Positive and negative likelihood ratios which, like sensitivity and specificity, are independent of disease prevalence. In most instances one can evaluate likelihood ratios across a range of possible values, unlike sensitivity and specificity which determine the crude presence and absence of a condition (<a href=\"image.htm?imageKey=OBGYN%2F69816\" class=\"graphic graphic_table graphicRef69816 \">table 3</a>). (See <a href=\"#H15\" class=\"local\">'What are the positive and negative likelihood ratios?'</a> above.)</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>If the sensitivity, specificity, and likelihood ratios are well defined, the penultimate factor determining the utility of a test is disease prevalence (<a href=\"topic.htm?path=calculator-post-test-probability-from-pre-test-probability-sensitivity-and-specificity\" class=\"calc calc_professional\">calculator 1</a> and <a href=\"topic.htm?path=calculator-post-test-probability-from-likelihood-ratios-and-multiple-test-results\" class=\"calc calc_professional\">calculator 2</a>). The usefulness of a positive test decreases as disease prevalence decreases. This concept is the basis of predictive values or post-test probabilities. (See <a href=\"#H16\" class=\"local\">'How well does the test perform in specific populations?'</a> above.)</p><p/><p class=\"bulletIndent1\"><span class=\"glyph\">&#9679;</span>The final judgment involved in considering the value of a test is the balance between cost of the disease and cost of the test. These costs involve charges to an individual, to an insurer, to an institution, or to society. Cost is often the determinant in deciding when, where, and how a diagnostic test is utilized. (See <a href=\"#H18\" class=\"local\">'What is the balance between cost of the disease and cost of the test?'</a> above.)</p></div><div id=\"topicAgreement\">Use of UpToDate is subject to the <a href=\"https://www.uptodate.com/legal/license\" class=\"licenseLink\" id=\"sla_in_page\">Subscription and License Agreement</a>.</div><div id=\"references\" class=\"headingAnchor\"><h1>REFERENCES</h1><ol id=\"reference\"><li><a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/abstract/1\" class=\"nounderline abstract_t\">Ewigman BG, Crane JP, Frigoletto FD, et al. Effect of prenatal ultrasound screening on perinatal outcome. RADIUS Study Group. N Engl J Med 1993; 329:821.</a></li><li><a href=\"https://www.uptodate.com/contents/evaluating-diagnostic-tests/abstract/2\" class=\"nounderline abstract_t\">Leitich H, Kaider A. Fetal fibronectin--how useful is it in the prediction of preterm birth? BJOG 2003; 110 Suppl 20:66.</a></li></ol></div><div id=\"topicVersionRevision\">Topic 2769 Version 16.0</div></div>","outline":"<div id=\"outlineSections\"><h2>Topic Outline</h2><ul id=\"innerOutline\"><li class=\"sr-button\"><a href=\"#H826056464\"><span>SUMMARY &amp; RECOMMENDATIONS</span></a></li><li><a href=\"#H1\" id=\"outline-link-H1\">INTRODUCTION</a></li><li><a href=\"#H2\" id=\"outline-link-H2\">CAN THE TEST BE PERFORMED RELIABLY?</a><ul><li><a href=\"#H3\" id=\"outline-link-H3\">Accuracy and precision</a></li><li><a href=\"#H4\" id=\"outline-link-H4\">Expertise</a></li></ul></li><li><a href=\"#H5\" id=\"outline-link-H5\">WAS THE TEST EVALUATED ON AN APPROPRIATE POPULATION?</a><ul><li><a href=\"#H6\" id=\"outline-link-H6\">Population</a></li><li><a href=\"#H7\" id=\"outline-link-H7\">Sample size</a></li></ul></li><li><a href=\"#H8\" id=\"outline-link-H8\">WAS AN APPROPRIATE REFERENCE-STANDARD USED?</a><ul><li><a href=\"#H9\" id=\"outline-link-H9\">Reference-standards</a></li><li><a href=\"#H10\" id=\"outline-link-H10\">Defining normal</a></li></ul></li><li><a href=\"#H11\" id=\"outline-link-H11\">WAS AN APPROPRIATE CUT-OFF VALUE CHOSEN TO OPTIMIZE SENSITIVITY AND SPECIFICITY?</a><ul><li><a href=\"#H12\" id=\"outline-link-H12\">Balancing sensitivity and specificity</a></li><li><a href=\"#H13\" id=\"outline-link-H13\">Two by two tables</a></li><li><a href=\"#H14\" id=\"outline-link-H14\">Receiver operating characteristic curves</a></li></ul></li><li><a href=\"#H15\" id=\"outline-link-H15\">WHAT ARE THE POSITIVE AND NEGATIVE LIKELIHOOD RATIOS?</a></li><li><a href=\"#H16\" id=\"outline-link-H16\">HOW WELL DOES THE TEST PERFORM IN SPECIFIC POPULATIONS?</a><ul><li><a href=\"#H17\" id=\"outline-link-H17\">Disease prevalence</a></li></ul></li><li><a href=\"#H18\" id=\"outline-link-H18\">WHAT IS THE BALANCE BETWEEN COST OF THE DISEASE AND COST OF THE TEST?</a></li><li><a href=\"#H826056464\" id=\"outline-link-H826056464\">SUMMARY AND RECOMMENDATIONS</a></li><li><a href=\"#references\">REFERENCES</a></li></ul></div><div><h2>GRAPHICS <a href=\"#\" id=\"viewAllGraphicsLink\">View All</a></h2><div id=\"outlineGraphics\"><ul><li><div id=\"PEDS/2769|FIG\" class=\"openRelatedGraphics\"><a href=\"#\" title=\"FIGURES\">FIGURES</a></div><ul><li><a href=\"image.htm?imageKey=OBGYN/73854\" class=\"graphic graphic_figure\">- Cut off value</a></li><li><a href=\"image.htm?imageKey=OBGYN/82175\" class=\"graphic graphic_figure\">- Sample ROC curve</a></li><li><a href=\"image.htm?imageKey=PC/68072\" class=\"graphic graphic_figure\">- Prevalence on PPV and NPV</a></li></ul></li><li><div id=\"PEDS/2769|TAB\" class=\"openRelatedGraphics\"><a href=\"#\" title=\"TABLES\">TABLES</a></div><ul><li><a href=\"image.htm?imageKey=PC/55297\" class=\"graphic graphic_table\">- Definition of accuracy</a></li><li><a href=\"image.htm?imageKey=OBGYN/73504\" class=\"graphic graphic_table\">- Two by two table</a></li><li><a href=\"image.htm?imageKey=OBGYN/69816\" class=\"graphic graphic_table\">- Positive vs neg likelihood</a></li><li><a href=\"image.htm?imageKey=GAST/77832\" class=\"graphic graphic_table\">- Definitions of sensitivity, specificity, PPV, and NPV</a></li><li><a href=\"image.htm?imageKey=OBGYN/51763\" class=\"graphic graphic_table\">- Prevalence vs PPV and NPV</a></li></ul></li></ul></div></div><div><h2>CALCULATORS</h2><div id=\"outlineCalculators\"><ul><li class=\"plainItem\"><a href=\"topic.htm?path=calculator-post-test-probability-from-pre-test-probability-sensitivity-and-specificity\" title=\"calculator 1\" class=\"calc calc_professional\">Calculator: Post Test Probability from Pre Test Probability, Sensitivity and Specificity</a></li><li class=\"plainItem\"><a href=\"topic.htm?path=calculator-post-test-probability-from-likelihood-ratios-and-multiple-test-results\" title=\"calculator 2\" class=\"calc calc_professional\">Calculator: Post-test probability from likelihood ratios and multiple test results</a></li></ul></div></div><div><h2>RELATED TOPICS</h2><div id=\"outlineTopics\"><ul><li class=\"plainItem\"><a href=\"topic.htm?path=evidence-based-approach-to-prevention\" class=\"medical medical_review\">Evidence-based approach to prevention</a></li><li class=\"plainItem\"><a href=\"topic.htm?path=glossary-of-common-biostatistical-and-epidemiological-terms\" class=\"medical medical_review\">Glossary of common biostatistical and epidemiological terms</a></li><li class=\"plainItem\"><a href=\"topic.htm?path=proof-p-values-and-hypothesis-testing\" class=\"medical medical_review\">Proof, p-values, and hypothesis testing</a></li></ul></div></div>","javascript":null}